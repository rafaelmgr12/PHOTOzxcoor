{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Photometric Redshift Estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will show how we can estimate the redshifts of galaxies using some machine learning methods. For this to be done, we will use data engineering techniques and thus be able to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.table import Table\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "from sklearn.model_selection import KFold,ShuffleSplit\n",
    "# Neural Network Libs\n",
    "\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout, Conv2D, MaxPooling2D, BatchNormalization, Activation\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import keras as ks\n",
    "from tensorflow.keras.constraints import max_norm\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import regularizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse_ann(y_true, y_pred):\n",
    "    diff = keras.backend.square(\n",
    "        (y_pred - y_true))\n",
    "    return keras.backend.sqrt(keras.backend.mean(diff))\n",
    "def get_features_targets2(data):\n",
    "    '''Extract the colors using the mag_derred.\n",
    "    Here I'm using the DES-mag, for other survey a change is needed'''\n",
    "    features = np.zeros(shape=(len(data), 5))\n",
    "\n",
    "    features[:, 0] = data['MAG_AUTO_G_DERED'].values - \\\n",
    "        data['MAG_AUTO_R_DERED'].values\n",
    "    features[:, 1] = data['MAG_AUTO_R_DERED'].values - \\\n",
    "        data['MAG_AUTO_I_DERED'].values\n",
    "    features[:, 2] = data['MAG_AUTO_I_DERED'].values - \\\n",
    "        data['MAG_AUTO_Z_DERED'].values\n",
    "    features[:, 3] = data['MAG_AUTO_Z_DERED'].values - \\\n",
    "        data['MAG_AUTO_Y_DERED'].values\n",
    "    #features[:, 4] = data['WAVG_MAG_PSF_G_DERED'].values - \\\n",
    "    #   data['WAVG_MAG_PSF_R_DERED'].values\n",
    "    #features[:, 5] = data['WAVG_MAG_PSF_R_DERED'].values - \\\n",
    "    #    data['WAVG_MAG_PSF_I_DERED'].values\n",
    "    #features[:, 6] = data['WAVG_MAG_PSF_I_DERED'].values - \\\n",
    "    #   data['WAVG_MAG_PSF_Z_DERED'].values\n",
    "    #features[:, 7] = data['WAVG_MAG_PSF_Z_DERED'].values - \\\n",
    "    #  data['WAVG_MAG_PSF_Y_DERED'].values\n",
    "\n",
    "    features[:, 4] = data[\"MAG_AUTO_I_DERED\"].values\n",
    "    #features[:, 9] = data[\"WAVG_MAG_PSF_I_DERED\"].values\n",
    "\n",
    "    targets = data['z'].values\n",
    "    return features, targets\n",
    "def tts_split(X, y, size, splits):\n",
    "    '''Split the data in Train and\n",
    "     test using the Shuffle split'''\n",
    "\n",
    "    rs = ShuffleSplit(n_splits=splits, test_size=size)\n",
    "\n",
    "    rs.get_n_splits(X)\n",
    "\n",
    "    for train_index, test_index in rs.split(X, y):\n",
    "        # print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Table.read(\"../input/vipers.fits\").to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "feat = ['MAG_AUTO_G','MAG_AUTO_R','MAG_AUTO_I','MAG_AUTO_Z','MAG_AUTO_Y',\n",
    "        'MAG_AUTO_G_DERED','MAG_AUTO_R_DERED','MAG_AUTO_I_DERED','MAG_AUTO_Z_DERED','MAG_AUTO_Y_DERED',\n",
    "        \"WAVG_MAG_PSF_G\",\"WAVG_MAG_PSF_R\",\"WAVG_MAG_PSF_I\",\"WAVG_MAG_PSF_Z\",\"WAVG_MAG_PSF_Y\"\n",
    "       ,'WAVG_MAG_PSF_G_DERED','WAVG_MAG_PSF_R_DERED','WAVG_MAG_PSF_I_DERED','WAVG_MAG_PSF_Z_DERED','WAVG_MAG_PSF_Y_DERED']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[data[feat[0]]==99,feat[0]] = data[data[feat[0]]!=99][feat[0]].max()\n",
    "data.loc[data[feat[1]]==99,feat[1]] = data[data[feat[1]]!=99][feat[1]].max()\n",
    "data.loc[data[feat[2]]==99,feat[2]] = data[data[feat[2]]!=99][feat[2]].max()\n",
    "data.loc[data[feat[3]]==99,feat[3]] = data[data[feat[3]]!=99][feat[3]].max()\n",
    "data.loc[data[feat[4]]==99,feat[4]] = data[data[feat[4]]!=99][feat[4]].max()\n",
    "data.loc[data[feat[5]]>90,feat[5]] = data[data[feat[5]]<90][feat[5]].max()\n",
    "data.loc[data[feat[6]]>90,feat[6]] = data[data[feat[6]]<90][feat[6]].max()\n",
    "data.loc[data[feat[7]]>90,feat[7]] = data[data[feat[7]]<90][feat[7]].max()\n",
    "data.loc[data[feat[8]]>90,feat[8]] = data[data[feat[8]]<90][feat[8]].max()\n",
    "data.loc[data[feat[9]]>90,feat[9]] = data[data[feat[9]]<90][feat[9]].max()\n",
    "data.loc[data[feat[10]]>90,feat[10]] = data[data[feat[10]]<90][feat[10]].max()\n",
    "data.loc[data[feat[11]]>90,feat[11]] = data[data[feat[11]]<90][feat[11]].max()\n",
    "data.loc[data[feat[12]]>90,feat[12]] = data[data[feat[12]]<90][feat[12]].max()\n",
    "data.loc[data[feat[13]]>90,feat[13]] = data[data[feat[13]]<90][feat[13]].max()\n",
    "data.loc[data[feat[14]]>90,feat[14]] = data[data[feat[14]]<90][feat[14]].max()\n",
    "data.loc[data[feat[15]]>90,feat[15]] = data[data[feat[15]]<90][feat[15]].max()\n",
    "data.loc[data[feat[16]]>90,feat[16]] = data[data[feat[16]]<90][feat[16]].max()\n",
    "data.loc[data[feat[17]]>90,feat[17]] = data[data[feat[17]]<90][feat[17]].max()\n",
    "data.loc[data[feat[18]]>90,feat[18]] = data[data[feat[18]]<90][feat[18]].max()\n",
    "data.loc[data[feat[19]]>90,feat[19]] = data[data[feat[19]]<90][feat[19]].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = get_features_targets2(data)\n",
    "y = y.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47658, 5)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discretize\n",
    "\n",
    "Here discretize data to obatain also the PDF's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "kbins = KBinsDiscretizer(200,encode = \"onehot\",strategy = \"uniform\")\n",
    "kbins.fit(y.reshape(-1,1))\n",
    "y_bins = kbins.transform(y.reshape(-1,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import hstack,vstack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47658, 201)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total = hstack([y_bins,y])\n",
    "y_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_total = y_total.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the mag for plot purpose only\n",
    "\n",
    "X = np.concatenate((X,data[['MAG_AUTO_G_DERED','MAG_AUTO_R_DERED','MAG_AUTO_I_DERED','MAG_AUTO_Z_DERED','MAG_AUTO_Y_DERED',]].values),axis = 1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47658, 201)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_total.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(47658, 10)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_inputs = X.shape[1]\n",
    "n_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ANN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "EarlyStop = EarlyStopping(monitor='reg_mse', mode='min', patience=20)\n",
    "BATCH_SIZE = 64\n",
    "STEPS_PER_EPOCH = len(data)//BATCH_SIZE\n",
    "lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
    "        0.0001,\n",
    "        decay_steps=STEPS_PER_EPOCH*1000,\n",
    "        decay_rate=1,\n",
    "        staircase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = keras.layers.Input(5)\n",
    "x = BatchNormalization()(inputs)\n",
    "x = Dense(20, kernel_initializer='normal',  kernel_constraint=max_norm(2.) ,activation='tanh',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                              bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)) (x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(15, kernel_initializer='normal',  kernel_constraint=max_norm(2.) ,activation='tanh',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                              bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)) (x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(10, kernel_initializer='normal',  kernel_constraint=max_norm(2.) ,activation='elu',kernel_regularizer=regularizers.l1_l2(l1=1e-5, l2=1e-4),\n",
    "                              bias_regularizer=regularizers.l2(1e-4),activity_regularizer=regularizers.l2(1e-5)) (x)\n",
    "output1 = Dense(1,activation = \"linear\",name = \"reg\") (x)\n",
    "output2 = Dense(200,activation = \"softmax\",name =\"pdf\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=[output1,output2], name=\"ann-photoz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"ann-photoz\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 5)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 5)            20          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 20)           120         batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 20)           80          dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 15)           315         batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 15)           60          dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 10)           160         batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "reg (Dense)                     (None, 1)            11          dense_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "pdf (Dense)                     (None, 200)          2200        dense_2[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,966\n",
      "Trainable params: 2,886\n",
      "Non-trainable params: 80\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#opt = ks.optimizers.Adamax(lr_schedule)\n",
    "opt = ks.optimizers.RMSprop(lr_schedule)\n",
    "model.compile(\n",
    "    loss={'reg': 'mean_absolute_error', \n",
    "                    'pdf': keras.losses.CategoricalCrossentropy()},loss_weights=[0.1,0.9],\n",
    "              optimizer=opt,\n",
    "              \n",
    "    metrics={'pdf': \"acc\",\n",
    "                      'reg': \"mse\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = tts_split(X,y_total,0.3,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n",
      "INFO:tensorflow:Assets written to: ../models/ann-1/assets\n",
      "Fold 2\n",
      "INFO:tensorflow:Assets written to: ../models/ann-2/assets\n",
      "Fold 3\n",
      "INFO:tensorflow:Assets written to: ../models/ann-3/assets\n",
      "Fold 4\n",
      "INFO:tensorflow:Assets written to: ../models/ann-4/assets\n",
      "Fold 5\n",
      "INFO:tensorflow:Assets written to: ../models/ann-5/assets\n",
      "Fold 6\n",
      "INFO:tensorflow:Assets written to: ../models/ann-6/assets\n",
      "Fold 7\n",
      "INFO:tensorflow:Assets written to: ../models/ann-7/assets\n",
      "Fold 8\n"
     ]
    }
   ],
   "source": [
    "folds = KFold(n_splits=10, shuffle=True, random_state=None)\n",
    "models = []\n",
    "pred = np.zeros(3336)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(X_train, y_train)):\n",
    "    fold_ += 1\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    X_t,y_t = X_train[trn_idx], y_train[trn_idx]\n",
    "    X_test,y_test = X_train[val_idx],y_train[val_idx]\n",
    "    # shape\n",
    "    # trainning\n",
    "    history = model.fit(X_t[:,:5], {'pdf': y_t[:,:200], 'reg': y_t[:,200]}, \n",
    "                    batch_size = 64,epochs= 256 ,validation_split = 0.2, callbacks=[EarlyStop],verbose = 0)\n",
    "    model_name = \"ann-\"+str(fold_)\n",
    "    model.save(\"../models/\"+model_name)\n",
    "    predictions = model.predict(X_test[:,:5])\n",
    "    rmse = np.sqrt(mean_squared_error(y_test[:,200],predictions[0]))\n",
    "    models.append({\"model\":model_name, \"rmse\": rmse})\n",
    "    pred += predictions[0].flatten()/ folds.n_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_model = keras.models.load_model(\"../models/ann-10\") # choose the minor value of rmse\n",
    "test_predictions = reconstructed_model.predict(X_test[:,:5])\n",
    "\n",
    "\n",
    "print(\"Testing set Mean Abs Error: {:5.4f} \".format(mean_absolute_error(y_test[:,200],test_predictions[0])))\n",
    "print(\"\\n\")\n",
    "print(\"Testing set Mean Square Error: {:5.4f} \".format(mean_squared_error(y_test[:,200],test_predictions[0])))\n",
    "print(\"\\n\")\n",
    "print(\"Testing set Root Mean Square Error: {:5.4f} \".format(np.sqrt(mean_squared_error(y_test[:,200],test_predictions[0]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zspec = y_test[:,200].flatten()\n",
    "zphot = test_predictions[0].flatten()\n",
    "pdf = test_predictions[1]\n",
    "x_plot = np.linspace(0,3.5,200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.hist2d(zspec,zphot, bins= 100,density=True,cmap = \"plasma\")\n",
    "plt.colorbar()\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.grid()\n",
    "#plt.show()\n",
    "#plt.savefig(\"plots/ann_hist2d.png\")\n",
    "##plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 8))\n",
    "plt.scatter(zspec, zphot, s=1, c=\"k\")\n",
    "plt.xlabel('True Values [MPG]')\n",
    "plt.ylabel('Predictions [MPG]')\n",
    "plt.axis('equal')\n",
    "plt.axis('square')\n",
    "plt.grid()\n",
    "_ = plt.plot([-100, 100], [-100, 100],color = \"red\")\n",
    "#plt.show()\n",
    "#plt.savefig(\"plots/scatter_ann.png\",dpi = 300)\n",
    "#plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import gaussian_kde\n",
    "plt.figure(figsize=(16,8))\n",
    "plt.title(\"Probabilty using KDE- Estimation\")\n",
    "xy = np.hstack([zspec.reshape(-1,1),zphot.reshape(-1,1)]).T\n",
    "z = gaussian_kde(xy)(xy)\n",
    "plt.scatter(zspec,zphot,c=z,s=5,cmap = \"viridis\")\n",
    "plt.xlabel(\"True Redshift\")\n",
    "plt.ylabel(\"Predicted Redshift\")\n",
    "plt.grid()\n",
    "plt.colorbar()\n",
    "#plt.savefig(\"plots/scatter_probs_ann_rafael.png\",dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.scatter(zspec,zphot,s=5,cmap = \"viridis\")\n",
    "plt.xlabel(\"True Redshift\")\n",
    "plt.ylabel(\"Predicted Redshift\")\n",
    "plt.grid()\n",
    "#plt.savefig(\"plots/scatter.ann_rafael.png\",dpi =300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "redshift = pd.DataFrame()\n",
    "redshift[\"z_phot\"] = zphot\n",
    "redshift[\"z_spec\"] = zspec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 1.) & (redshift[\"z_phot\"] < 1.5)][\"z_spec\"].values,label = \"1.<z<1.5\",bins = 100, color = \"b\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.9) & (redshift[\"z_phot\"] < 1.)][\"z_spec\"].values,label = \"0.9<z<1.0\",bins = 100,color = \"r\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.8) & (redshift[\"z_phot\"] < 0.9)][\"z_spec\"].values,label = \"0.8<z<0.9\",bins = 100,color = \"g\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.7) & (redshift[\"z_phot\"] < 0.8)][\"z_spec\"].values,label = \"0.7<z<0.8\",bins = 100,color = \"yellow\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.6) & (redshift[\"z_phot\"] < 0.7)][\"z_spec\"].values,label = \"0.6<z<0.7\",bins = 100,color = \"brown\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.5) & (redshift[\"z_phot\"] < 0.6)][\"z_spec\"].values,label = \"0.5<z<0.6\",bins = 100,color = \"pink\")\n",
    "plt.hist(redshift[redshift[\"z_phot\"] < 0.5][\"z_spec\"].values,label = \"z<0.5\",bins = 100)\n",
    "plt.xlabel(\"Redshift spectoscopic\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.hist(redshift[redshift[\"z_phot\"] < 0.5][\"z_spec\"].values,label = \"z<0.5\",bins = 100)\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.5) & (redshift[\"z_phot\"] < 0.6)][\"z_spec\"].values,label = \"0.5<z<0.6\",bins = 100,color = \"pink\" )\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.6) & (redshift[\"z_phot\"] < 0.7)][\"z_spec\"].values,label = \"0.6<z<0.7\",bins = 100,color = \"brown\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.7) & (redshift[\"z_phot\"] < 0.8)][\"z_spec\"].values,label = \"0.7<z<0.8\",bins = 100,color = \"yellow\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.8) & (redshift[\"z_phot\"] < 0.9)][\"z_spec\"].values,label = \"0.8<z<0.9\",bins = 100,color = \"g\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 0.9) & (redshift[\"z_phot\"] < 1.)][\"z_spec\"].values,label = \"0.9<z<1.0\",bins = 100,color = \"r\")\n",
    "plt.hist(redshift[(redshift[\"z_phot\"] > 1.) & (redshift[\"z_phot\"] < 1.5)][\"z_spec\"].values,label = \"1.<z<1.5\",bins = 100,color = \"b\")\n",
    "plt.xlabel(\"Redshift spectoscopic\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
